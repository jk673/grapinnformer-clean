{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c82d9c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyg-lib ok; 0.4.0+pt25cu118\n",
      "Torch: 2.5.1\n",
      "CUDA: 11.8\n",
      "PyVista: 0.46.1\n",
      "PyG: 2.6.1\n",
      "py  : 3.10.18\n"
     ]
    }
   ],
   "source": [
    "# 1. Environment & dependencies\n",
    "import gc\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from itertools import chain\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as cp\n",
    "from torch import Tensor\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader, NeighborLoader\n",
    "from torch_geometric.nn import GCNConv, GraphNorm, JumpingKnowledge, TransformerConv\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "import pyg_lib\n",
    "\n",
    "# Data and model settings\n",
    "DATA_ROOT = Path('data')\n",
    "TARGET_FIELD = 'static(p)_coeffMean'\n",
    "USE_NORMALS = True\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(\"pyg-lib ok;\", getattr(pyg_lib, \"__version__\", \"ok\"))\n",
    "print('Torch:', torch.__version__)\n",
    "print('CUDA:', torch.version.cuda)\n",
    "print('PyVista:', pv.__version__)\n",
    "print('PyG:', torch_geometric.__version__ if 'torch_geometric' in sys.modules else 'unknown')\n",
    "print(\"py  :\", sys.version.split()[0])  # ex) 3.11.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c23b9",
   "metadata": {},
   "source": [
    "## Load Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76c3b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"graphs_cache_slim.pt\"\n",
    "\n",
    "# torch로 로드\n",
    "model_state = torch.load(file_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead6264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graphs, val_graphs = model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abc9461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e29457b2a8d428891d307cfc09e9950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "to_pyg:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3424b85ed5124479bbc0e86b3e1d8cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "to_pyg:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def to_pyg(graphs):\n",
    "    out = []\n",
    "    for g in tqdm(graphs, desc='to_pyg'):\n",
    "        if isinstance(g, dict):\n",
    "            x = torch.tensor(g['x'], dtype=torch.float32)\n",
    "            edge_index = torch.tensor(g['edge_index'], dtype=torch.long)\n",
    "            y = torch.tensor(g['y'], dtype=torch.float32)\n",
    "            out.append(Data(x=x, edge_index=edge_index, y=y))\n",
    "        else:\n",
    "            out.append(g)\n",
    "    return out\n",
    "\n",
    "train_graphs = to_pyg(train_graphs)\n",
    "val_graphs   = to_pyg(val_graphs)\n",
    "\n",
    "# PyG Data로 변환된 뒤에 한 번만 실행\n",
    "for lst in (train_graphs, val_graphs):\n",
    "    for d in lst:\n",
    "        if getattr(d, 'pos', None) is None:\n",
    "            d.pos = d.x[:, :3].contiguous()   # x = [xyz,(normals...)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea601e3a",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "351599f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공용 옵션(줄 폭/갱신간격/TTY 아닌 환경 자동 비활성화)\n",
    "_TQDM_KW = dict(\n",
    "    ncols=100,                 # 줄바꿈 방지 (원하면 120~140)\n",
    "    dynamic_ncols=False,       # 고정 폭이 깔끔\n",
    "    mininterval=0.25,          # 너무 잦은 갱신 방지\n",
    "    smoothing=0.1,\n",
    "    bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} {rate_fmt} {postfix}\",\n",
    "    disable=not sys.stdout.isatty()  # 로그 캡처/파일일 땐 자동 끔\n",
    ")\n",
    "\n",
    "def _bar(total, desc, position, leave):\n",
    "    return tqdm(total=total, desc=desc, position=position, leave=leave, **_TQDM_KW)\n",
    "\n",
    "\n",
    "def _mkbar(total, desc, position=0, leave=False, progress=True):\n",
    "    if not progress:\n",
    "        return None  # 진행바 비활성화\n",
    "    return tqdm(\n",
    "        total=total, desc=desc, position=position, leave=leave,\n",
    "        ncols=100, dynamic_ncols=False, mininterval=0.25, smoothing=0.1,\n",
    "        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} {rate_fmt} {postfix}\"\n",
    "    )\n",
    "\n",
    "def _update(bar, n=1, postfix=None):\n",
    "    if bar is None: return\n",
    "    if postfix is not None:\n",
    "        if isinstance(postfix, dict): bar.set_postfix(postfix)\n",
    "        else: bar.set_postfix_str(str(postfix))\n",
    "    bar.update(n)\n",
    "\n",
    "def _close(bar):\n",
    "    if bar is not None: bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b99a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_csr_from_edge_index_no_torch_sparse(edge_index: Tensor, num_nodes: int,\n",
    "                                              make_undirected: bool=True) -> Tuple[Tensor, Tensor]:\n",
    "    assert edge_index.dtype == torch.long, f\"dtype must be torch.long, got {edge_index.dtype}\"\n",
    "    assert edge_index.dim() == 2 and edge_index.size(0) == 2, f\"edge_index shape must be [2, E], got {tuple(edge_index.shape)}\"\n",
    "\n",
    "    row0 = edge_index[0].contiguous()\n",
    "    col0 = edge_index[1].contiguous()\n",
    "\n",
    "    if make_undirected:\n",
    "        row = torch.cat([row0, col0], dim=0)\n",
    "        col = torch.cat([col0, row0], dim=0)\n",
    "    else:\n",
    "        row, col = row0, col0\n",
    "\n",
    "    assert row.numel() == col.numel(), f\"row({row.numel()}) and col({col.numel()}) must match\"\n",
    "\n",
    "    # 행-열 키로 정렬\n",
    "    stride = num_nodes\n",
    "    key = row * stride + col\n",
    "    perm = torch.argsort(key)\n",
    "    row = row[perm]\n",
    "    col = col[perm]\n",
    "\n",
    "    deg = torch.bincount(row, minlength=num_nodes)\n",
    "    rowptr = torch.empty(num_nodes + 1, dtype=torch.long)\n",
    "    rowptr[0] = 0\n",
    "    rowptr[1:] = torch.cumsum(deg, dim=0)\n",
    "    assert col.numel() == rowptr[-1].item(), \"CSR col length must equal rowptr[-1]\"\n",
    "    return rowptr, col.contiguous()\n",
    "\n",
    "\n",
    "\n",
    "from typing import List\n",
    "\n",
    "@torch.no_grad()\n",
    "def batched_khop_cover_pure_with_progress(\n",
    "    rowptr, col, num_nodes, *,\n",
    "    min_nodes=4096, k0=3, k_max=5, seeds_per_iter=512,\n",
    "    early_cut_ratio=1.10, overlap_ratio=0.2, seed=1234,\n",
    "    progress=True, gid=0\n",
    "):\n",
    "    g = torch.Generator(device='cpu'); g.manual_seed(seed)\n",
    "    uncovered = torch.ones(num_nodes, dtype=torch.bool)\n",
    "    order = torch.randperm(num_nodes, generator=g)\n",
    "    ptr = 0; patches = []\n",
    "\n",
    "    # 같은 라인 번호 고정(깨끗한 화면 유지)\n",
    "    bar_scan = _mkbar(num_nodes, f\"[g{gid}] scan\", position=2, leave=False, progress=progress)\n",
    "    bar_cov  = _mkbar(num_nodes, f\"[g{gid}] covered\", position=1, leave=False, progress=progress)\n",
    "    prev_cov = 0\n",
    "\n",
    "    def neighbors_of(frontier_idx):\n",
    "        starts = rowptr[frontier_idx]; ends = rowptr[frontier_idx+1]\n",
    "        counts = (ends - starts)\n",
    "        if counts.sum().item() == 0: return torch.empty(0, dtype=torch.long)\n",
    "        off = torch.empty_like(counts); off[0]=0\n",
    "        if counts.numel()>1: off[1:] = torch.cumsum(counts[:-1], dim=0)\n",
    "        total = counts.sum().item()\n",
    "        buf = torch.empty(total, dtype=torch.long)\n",
    "        for s,e,o in zip(starts.tolist(), ends.tolist(), off.tolist()):\n",
    "            if e>s: buf[o:o+(e-s)] = col[s:e]\n",
    "        return torch.unique(buf)\n",
    "\n",
    "    while ptr < num_nodes and uncovered.any():\n",
    "        batch = []; scanned=0\n",
    "        while len(batch) < seeds_per_iter and ptr < num_nodes:\n",
    "            u = order[ptr].item(); ptr += 1; scanned += 1\n",
    "            if uncovered[u]: batch.append(u)\n",
    "        if scanned: _update(bar_scan, scanned)\n",
    "        if not batch: break\n",
    "        batch = torch.tensor(batch, dtype=torch.long)\n",
    "\n",
    "        mask = torch.zeros(num_nodes, dtype=torch.bool); frontier = batch; k=0\n",
    "        while True:\n",
    "            mask[frontier] = True\n",
    "            if k>=k0 and mask.sum().item() >= int(min_nodes*early_cut_ratio): break\n",
    "            if k==k_max: break\n",
    "            neighs = neighbors_of(frontier)\n",
    "            if neighs.numel()==0: break\n",
    "            cand = neighs[~mask[neighs]]\n",
    "            if cand.numel()==0: break\n",
    "            frontier = cand; k += 1\n",
    "\n",
    "        chosen = mask.nonzero(as_tuple=False).view(-1)\n",
    "        if chosen.numel() > min_nodes:\n",
    "            perm = torch.randperm(chosen.numel(), generator=g)[:min_nodes]\n",
    "            chosen = chosen[perm]\n",
    "        patches.append(chosen)\n",
    "\n",
    "        if chosen.numel()>0:\n",
    "            take = torch.rand(chosen.size(0), generator=g) > overlap_ratio\n",
    "            uncovered[chosen[take]] = False\n",
    "\n",
    "        now_cov = (num_nodes - uncovered.sum().item())\n",
    "        _update(bar_cov, now_cov - prev_cov, postfix=f\"patches={len(patches)} k={k}\")\n",
    "        prev_cov = now_cov\n",
    "\n",
    "    _close(bar_scan); _close(bar_cov)\n",
    "    return patches\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def fast_make_subgraph_pure(g: Data, node_idx: Tensor) -> Data:\n",
    "    node_idx = node_idx.unique()\n",
    "    mask = torch.zeros(g.num_nodes, dtype=torch.bool)\n",
    "    mask[node_idx] = True\n",
    "\n",
    "    ei = g.edge_index\n",
    "    e_mask = mask[ei[0]] & mask[ei[1]]\n",
    "    sub_edge = ei[:, e_mask]\n",
    "\n",
    "    new_id = torch.full((g.num_nodes,), -1, dtype=torch.long)\n",
    "    new_id[mask] = torch.arange(mask.sum(), dtype=torch.long)\n",
    "    sub_edge = new_id[sub_edge]\n",
    "\n",
    "    sub = Data()\n",
    "    # 원본 E(엣지 수)\n",
    "    E = ei.size(1)\n",
    "\n",
    "    for k, v in g.items():\n",
    "        if k == \"edge_index\":\n",
    "            sub.edge_index = sub_edge\n",
    "            continue\n",
    "\n",
    "        if torch.is_tensor(v):\n",
    "            # 1) node-level: [N, ...]\n",
    "            if v.size(0) == g.num_nodes:\n",
    "                sub[k] = v[mask]\n",
    "                continue\n",
    "            # 2) edge-level: [E, ...]\n",
    "            if v.size(0) == E:\n",
    "                sub[k] = v[e_mask]\n",
    "                continue\n",
    "            # 3) graph-level scalar/벡터 (크기 1 또는 배치 없음)\n",
    "            if v.numel() == v.shape[0] and v.shape[0] == 1:\n",
    "                sub[k] = v\n",
    "                continue\n",
    "            # 4) 그 외(예: y_graph 같은 그래프 레벨 텐서)\n",
    "            #   - shape이 [G, ...]로 오면 그대로 둡니다(단일 그래프 가정).\n",
    "            sub[k] = v\n",
    "        else:\n",
    "            sub[k] = v\n",
    "            \n",
    "    return sub\n",
    "\n",
    "\n",
    "from os import PathLike\n",
    "from typing import Union, List\n",
    "import torch\n",
    "from torch import Tensor\n",
    "AnyPath = Union[str, bytes, PathLike]\n",
    "\n",
    "def save_indices_packed(patches: List[Tensor], save_path: AnyPath, *, progress=True, position=3):\n",
    "    sizes = [p.numel() for p in patches]\n",
    "    ptr = torch.zeros(len(patches) + 1, dtype=torch.long)\n",
    "    if sizes: ptr[1:] = torch.cumsum(torch.tensor(sizes, dtype=torch.long), dim=0)\n",
    "    nodes = torch.empty(ptr[-1].item(), dtype=torch.long)\n",
    "    off = 0\n",
    "\n",
    "    bar = _mkbar(len(patches), \"[cache] save patches\", position=position, leave=False, progress=progress)\n",
    "    for p in patches:\n",
    "        n = p.numel(); nodes[off:off+n] = p; off += n\n",
    "        _update(bar, 1)\n",
    "    _close(bar)\n",
    "    torch.save({\"ptr\": ptr, \"nodes\": nodes}, save_path)\n",
    "\n",
    "def load_indices_packed(save_path: AnyPath, *, progress=True, position=3) -> List[Tensor]:\n",
    "    obj = torch.load(save_path, map_location='cpu')\n",
    "    ptr, nodes = obj[\"ptr\"], obj[\"nodes\"]\n",
    "    out: List[Tensor] = []\n",
    "    bar = _mkbar(ptr.numel()-1, \"[cache] load patches\", position=position, leave=False, progress=progress)\n",
    "    for i in range(ptr.numel()-1):\n",
    "        lo, hi = ptr[i].item(), ptr[i+1].item()\n",
    "        out.append(nodes[lo:hi].clone())\n",
    "        _update(bar, 1)\n",
    "    _close(bar)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cb9c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_patch_loader_pure(\n",
    "    graphs: List[Data],\n",
    "    min_nodes=4096, save_root=None,\n",
    "    batch_size=4, shuffle=True, num_workers=0,\n",
    "    k0=3, k_max=5, seeds_per_iter=1024,\n",
    "    early_cut_ratio=1.10, overlap_ratio=0.2, seed=42,\n",
    "    *, progress=True, return_list=False\n",
    ") -> Tuple[iter, int]:\n",
    "\n",
    "    loaders = []\n",
    "    len_epoch = 0\n",
    "    bar_graphs = _mkbar(len(graphs), \"[graphs]\", position=0, leave=True, progress=progress)\n",
    "\n",
    "    for gid, g in enumerate(graphs):\n",
    "        cache_dir = Path(save_root) / f\"graph_{gid}\" if save_root else None\n",
    "        packed = cache_dir / \"patch_indices.pth\" if cache_dir else None\n",
    "\n",
    "        if cache_dir and packed.exists():\n",
    "            patches = load_indices_packed(packed, progress=progress, position=3)\n",
    "        else:\n",
    "            # CSR (여긴 표시 1칸만 점유)\n",
    "            bar_csr = _mkbar(1, f\"[g{gid}] build CSR\", position=3, leave=False, progress=progress)\n",
    "            rowptr, col = build_csr_from_edge_index_no_torch_sparse(\n",
    "                g.edge_index.cpu().long(), g.num_nodes, make_undirected=True\n",
    "            )\n",
    "            _update(bar_csr, 1); _close(bar_csr)\n",
    "\n",
    "            patches = batched_khop_cover_pure_with_progress(\n",
    "                rowptr=rowptr, col=col, num_nodes=g.num_nodes,\n",
    "                min_nodes=min_nodes, k0=k0, k_max=k_max, seeds_per_iter=seeds_per_iter,\n",
    "                early_cut_ratio=early_cut_ratio, overlap_ratio=overlap_ratio, seed=seed,\n",
    "                progress=progress, gid=gid\n",
    "            )\n",
    "            if cache_dir:\n",
    "                cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "                save_indices_packed(patches, packed, progress=progress, position=3)\n",
    "\n",
    "        # Subgraph build (한 줄)\n",
    "        bar_subs = _mkbar(len(patches), f\"[g{gid}] make subgraphs\", position=3, leave=False, progress=progress)\n",
    "        subs = []\n",
    "        for idx in patches:\n",
    "            subs.append(fast_make_subgraph_pure(g, idx))\n",
    "            _update(bar_subs, 1)\n",
    "        _close(bar_subs)\n",
    "\n",
    "        ld = DataLoader(subs, batch_size=batch_size, shuffle=shuffle,\n",
    "                        num_workers=num_workers, pin_memory=True)\n",
    "        loaders.append(ld)\n",
    "        _update(bar_graphs, 1)\n",
    "        len_epoch += len(ld)\n",
    "\n",
    "    _close(bar_graphs)\n",
    "\n",
    "    if return_list:\n",
    "        return loaders, len_epoch\n",
    "    \n",
    "    else:\n",
    "        return chain(*loaders), len_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dfcd0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA cache cleared.\n",
      "Garbage collected.\n"
     ]
    }
   ],
   "source": [
    "# Clear CUDA cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"CUDA cache cleared.\")\n",
    "\n",
    "# Collect garbage\n",
    "gc.collect()\n",
    "print(\"Garbage collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c17edb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096a255437aa4d0983f1ae89dd2ed94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[graphs]:   0%|                                                                         | 0/3 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76926c49e2241f7bcdf68b77511b5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g0] build CSR:   0%|                                                                   | 0/1 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eef89dd53a8468d98ec3c95474c674f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g0] scan:   0%|                                                                  | 0/1292868 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d706f90a8f542c990798cb3a19e890d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g0] covered:   0%|                                                               | 0/1292868 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92c676c334d4b74b3d7c7501de9dc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cache] save patches:   0%|                                                           | 0/663 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c376abba737f4e1495f5fa947a4f0dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g0] make subgraphs:   0%|                                                            | 0/663 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d0065b75544165bdce64ef75b25d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g1] build CSR:   0%|                                                                   | 0/1 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2264a77872594d9792561a0c434f4597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g1] scan:   0%|                                                                   | 0/962658 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f2711834fe4c679372c8f1e917a5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g1] covered:   0%|                                                                | 0/962658 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fffa98dffb4d1489626092765f1404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cache] save patches:   0%|                                                           | 0/494 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd80bc73f3ca4deab023511a00be577a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g1] make subgraphs:   0%|                                                            | 0/494 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cc84c3d60e40f6bb627c1134651cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g2] build CSR:   0%|                                                                   | 0/1 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d930c0d77c428097602b6edf70d089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g2] scan:   0%|                                                                  | 0/1268335 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e05e062def43b7ba3f30618d598bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g2] covered:   0%|                                                               | 0/1268335 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad1017c3b3346a6a294c4d897c76b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cache] save patches:   0%|                                                           | 0/651 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9939f48dbb84b0cb203375aa18cf1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g2] make subgraphs:   0%|                                                            | 0/651 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11c1ae9a14e4a788f7584d3de0807dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[graphs]:   0%|                                                                         | 0/1 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3425eb0ec741446093931f6a252e21ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g0] build CSR:   0%|                                                                   | 0/1 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34c92e08b064ce8a86dbef1b9cf949c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g0] scan:   0%|                                                                  | 0/1131049 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5bba04fec8342c997c676f681c447ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g0] covered:   0%|                                                               | 0/1131049 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe117bb7987468d9960fe8a46b4af8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cache] save patches:   0%|                                                           | 0/580 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7ef34f008443a993a1d27a6dd8f2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[g0] make subgraphs:   0%|                                                            | 0/580 ?it/s "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_epoch: 77 len_val: 25\n"
     ]
    }
   ],
   "source": [
    "train_loader, len_epoch = cluster_patch_loader_pure(\n",
    "    train_graphs, save_root=\"cache/train\",\n",
    "    min_nodes=3072, batch_size=24, num_workers=4,\n",
    "    k0=3, k_max=5, seeds_per_iter=1024,\n",
    "    early_cut_ratio=1.08, overlap_ratio=0.25, seed=42,\n",
    "    progress=True, return_list=True\n",
    ")\n",
    "\n",
    "val_loader, len_val  = cluster_patch_loader_pure(\n",
    "    val_graphs,\n",
    "    save_root=\"cache/val\",\n",
    "    min_nodes=3072, batch_size=24, num_workers=4,\n",
    "    k0=3, k_max=5, seeds_per_iter=1024,\n",
    "    early_cut_ratio=1.08, overlap_ratio=0.25, seed=42,\n",
    "    progress=True, return_list=True\n",
    ")\n",
    "\n",
    "\n",
    "print(\"len_epoch:\", len_epoch, \"len_val:\", len_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77b2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jyk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
